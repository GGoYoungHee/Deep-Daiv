# Deep-Daiv

- 기간 : 2021.12.15 ~ 2022.03.24
- Personal Goal : 
  1. How to Explain Simply 
  2. Survive

# week 1 : OT
- False Positive (X)
- True Positivie (O)
- Goal: 10k
- Slack & Notion
- 10h per week

# week 2
- What is GA?
- LaTeX Writing
- Jekyll: Static Generator -> 컨텐츠를 html(static websites)로 변환시키기, github 내부에도 설치됨
  - markdown파일로 글 작성, git push로 업로드, Github pages 내부 Jekyll이 이를 인식한 후 html로 변환후 웹 호스팅  
- Static Website: 어떤 웹사이트 주소를 접속한다면 모든 사람들이 모든 결과물(html)이 동일

# week 3
- [paper] Character-level CNN
- https://arxiv.org/abs/1509.01626
- CNN=Vision이라는 편견 깨기 
- CNN을 NLP에 적용시키기 with code

# week 4
- [paper] Going Deeper with Convolutions
- https://arxiv.org/abs/1409.4842
- GoogleNet이라고도 불리는 모델 -> ILSVRC에서 SOTA 달성했지만, 레이어가 너무 깊어 공동 1위한 VGGNet에 좀 더 집중함.
- 하지만 그 다음 챌린지인 2015 ILSVRC에서 SOTA를 달성한 모델이 152개의 레이어를 갖는걸 보면, layer 22인 GoogleNet이 영향을 줬을 거라고 생각한다...!
- Deep Learning Architecture 자세히 샅샅이 뜯어봄! 
- 코드도 돌려봤지만, 이전 CNN 공부 방향과는 다르게 '코드 구현'을 집중적으로 하지 않고 Architecture에 집중하며, Parameter에 집중함.
- 1\*1 Conv layer
- Inception

# week 5
- Reinforcement Learning foundation
- not paper
- 통계학의 시선으로 강화학습 바라보기

# week 6
- [paper] Play Atari with deep reinforcement learning
- https://arxiv.org/abs/1312.5602
- RL with CNN
- 즉 컴퓨터가 실제로 이미지 데이터를 보면서 스스로 학습해 게임 실행 
![Untitled](https://user-images.githubusercontent.com/77769026/153120158-d0bc5fe9-cbd0-4467-99ae-b6143f18ac16.png)


# week 7
- [paper] Human-level control through deep reinforcement learning
- https://www.nature.com/articles/nature14236




